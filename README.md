# Book2SocialFeed ğŸ“šâ¡ï¸ğŸ“±

This Python script extracts text from PDF files, splits it into chunks, and saves the chunks as both JSON and HTML files. It's useful for processing large documents and preparing text data for further analysis or processing, such as creating social media content from books.

## Features ğŸŒŸ

- Extracts text from PDF files ğŸ“„
- Saves text as JSON and HTML files ğŸ“Š

## Roadmap ğŸ›£ï¸

- [x] Accept input from file explorer.
- [ ] Add a web interface.
- [ ] Improve chunking with AI models.

## Requirements ğŸ› ï¸

- Python 3.6+
- PyPDF2 library
- PyQt5

## Installation ğŸš€

1. Clone this repository:

   ```bash
   git clone https://github.com/thethmuu/book2socialfeed.git
   ```

2. Navigate to the project directory:

   ```bash
   cd book2socialfeed
   ```

3. Install the required packages:

   ```bash
   pip install -r requirements.txt
   ```

## Usage ğŸ–¥ï¸

1. Run the script:

   ```bash
   python main.py
   ```

2. Enter the following prompts:

   - PDF file name ğŸ“
   - Number of pages to skip (default is 1) â­ï¸
   - Chunk size (default is 50) ğŸ“

3. The script generates:
   - `output.json`: Extracted text chunks
   - `output.html`: Basic styled representation of the chunks

## Output ğŸ“Š

- `output.json` contains an array of text chunks.
- `output.html` displays the text chunks in a simple format.

## Customization âš™ï¸

Modify `chunk_size` and `skip_pages` in the script for different defaults.

## Contributing ğŸ¤

Contributions and feature requests are welcome! Check the [issues page](https://github.com/thethmuu/book2socialfeed/issues).

## License ğŸ“œ

This project is [MIT](https://choosealicense.com/licenses/mit/) licensed.
